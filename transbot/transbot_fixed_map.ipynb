{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "\n",
    "def c_slope(x1, y1, x2, y2):\n",
    "    \"\"\"计算斜率\n",
    "\n",
    "    Args:\n",
    "        x1 (float): 第一个点的x坐标\n",
    "        y1 (float): 第一个点的y坐标\n",
    "        x2 (float): 第二个点的x坐标\n",
    "        y2 (float): 第二个点的y坐标\n",
    "\n",
    "    Returns:\n",
    "        float: 斜率角的弧度\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 斜率k\n",
    "        k = float(y2 - y1) / float(x2 - x1)\n",
    "        theta_rad = math.atan(k)\n",
    "        # res = theta * (180 / math.pi) # 弧度转角度\n",
    "    except ZeroDivisionError:\n",
    "        # 垂直线\n",
    "        theta_rad = math.pi / 2\n",
    "        # res = theta * (180 / math.pi)\n",
    "    return theta_rad\n",
    "\n",
    "\n",
    "def region_of_interest(edges, direction='left'):\n",
    "    height, width = edges.shape\n",
    "    mask = np.zeros_like(edges)\n",
    "    # 定义感兴趣区域掩码轮廓，决定了进行识别的视野范围\n",
    "    if direction == 'left':\n",
    "        # 多边形的四个点\n",
    "        polygon = np.array([[(0, height * 1 / 2),\n",
    "                             (width * 1 / 2, height * 1 / 2),\n",
    "                             (width * 1 / 2, height),\n",
    "                             (0, height)]], np.int32)\n",
    "    else:\n",
    "        polygon = np.array([[(width * 1 / 2, height * 1 / 2),\n",
    "                             (width, height * 1 / 2),\n",
    "                             (width, height),\n",
    "                             (width * 1 / 2, height)]], np.int32)\n",
    "    # 填充感兴趣区域掩码\n",
    "    cv2.fillPoly(mask, polygon, 255)\n",
    "    # 提取感兴趣区域\n",
    "    croped_edge = cv2.bitwise_and(edges, mask)\n",
    "    return croped_edge\n",
    "\n",
    "\n",
    "def detect_line(edges):\n",
    "    '''\n",
    "    基于霍夫变换的直线检测\n",
    "    '''\n",
    "    rho = 1  # 距离精度：1像素\n",
    "    angle = np.pi / 180  # 角度精度：1度\n",
    "    min_thr = 10  # 最少投票数\n",
    "    lines = cv2.HoughLinesP(edges,\n",
    "                            rho,\n",
    "                            angle,\n",
    "                            min_thr,\n",
    "                            np.array([]),\n",
    "                            minLineLength=8,\n",
    "                            maxLineGap=8)\n",
    "    return lines\n",
    "\n",
    "def make_points(frame, line):\n",
    "    '''\n",
    "    根据直线斜率和截距计算线段起始坐标\n",
    "    '''\n",
    "    height, width, _ = frame.shape\n",
    "    slope, intercept = line\n",
    "    y1 = height\n",
    "    y2 = int(y1 * 1 / 2)\n",
    "    x1 = max(-width, min(2 * width, int((y1 - intercept) / slope)))\n",
    "    x2 = max(-width, min(2 * width, int((y2 - intercept) / slope)))\n",
    "    return [[x1, y1, x2, y2]]\n",
    "\n",
    "\n",
    "\n",
    "def average_lines_old(frame, lines, direction='middle'):\n",
    "    # https://blog.csdn.net/yang332233/article/details/122120160\n",
    "    '''\n",
    "    小线段聚类\n",
    "    direction: left or right or middle\n",
    "    '''\n",
    "    lane_lines = []\n",
    "    if lines is None:\n",
    "        print('没有检测到线段')\n",
    "        return lane_lines\n",
    "    height, width, _ = frame.shape\n",
    "    fits = []\n",
    "\n",
    "    for line in lines:\n",
    "        for x1, y1, x2, y2 in line:\n",
    "            if x1 == x2:\n",
    "                continue\n",
    "            # 计算拟合直线\n",
    "            fit = np.polyfit((x1, x2), (y1, y2), 1)\n",
    "            slope = fit[0]\n",
    "            intercept = fit[1]\n",
    "            if direction == 'left' and slope < 0:\n",
    "                fits.append((slope, intercept))\n",
    "            elif direction == 'right' and slope > 0:\n",
    "                fits.append((slope, intercept))\n",
    "            elif direction == 'middle':\n",
    "                fits.append((slope, intercept))\n",
    "    if len(fits) > 0:\n",
    "        fit_average = np.average(fits, axis=0)\n",
    "        lane_lines.append(make_points(frame, fit_average))\n",
    "    return lane_lines\n",
    "\n",
    "def average_lines(frame, lines, direction='left'):\n",
    "    # https://blog.csdn.net/yang332233/article/details/122120160\n",
    "    '''\n",
    "    小线段聚类, 聚类时忽略掉斜率在tan(0) - tan(pi/6)和tan(pi * 5/ 6) - tan(pi)之间的线段\n",
    "    '''\n",
    "    lane_lines = []\n",
    "    if lines is None:\n",
    "        print(direction + '没有检测到线段')\n",
    "        return lane_lines\n",
    "    height, width, _ = frame.shape\n",
    "    fits = []\n",
    "\n",
    "    for line in lines:\n",
    "        for x1, y1, x2, y2 in line:\n",
    "            if x1 == x2:\n",
    "                continue\n",
    "            k = c_slope(x1, y1, x2, y2)\n",
    "            # 丢弃斜率在tan(0) - tan(pi/6)或tan(pi * 5/ 6) - tan(pi)之间的线段\n",
    "            if (k > math.tan(0) and k < math.tan(math.pi / 2)) or (k > math.tan(math.pi * 3 / 4) and k < math.tan(math.pi)):\n",
    "                continue\n",
    "            # 计算拟合直线\n",
    "            fit = np.polyfit((x1, x2), (y1, y2), 1)\n",
    "            slope = fit[0]\n",
    "            intercept = fit[1]\n",
    "            if direction == 'left' and slope < 0:\n",
    "                fits.append((slope, intercept))\n",
    "            elif direction == 'right' and slope > 0:\n",
    "                fits.append((slope, intercept))\n",
    "    if len(fits) > 0:\n",
    "        fit_average = np.average(fits, axis=0)\n",
    "        lane_lines.append(make_points(frame, fit_average))\n",
    "    return lane_lines\n",
    "\n",
    "def FitPolynomialCurve(img, n=5):\n",
    "    '''\n",
    "    拟合曲线\n",
    "    '''\n",
    "    h, w = img.shape[:2]\n",
    "    x = np.linspace(0, w - 1, w)\n",
    "    y = np.linspace(0, h - 1, h)\n",
    "    y, x = np.meshgrid(y, x)\n",
    "    x = x.flatten()\n",
    "    y = y.flatten()\n",
    "    A = np.ones((len(x), n + 1))\n",
    "    for i in range(1, n + 1):\n",
    "        A[:, i] = x ** i\n",
    "    coeffs = np.linalg.lstsq(A, y, rcond=None)[0]\n",
    "    return coeffs\n",
    "\n",
    "\n",
    "def display_line(frame, lines, line_color=(0, 0, 255), line_width=2):\n",
    "    '''\n",
    "    在原图上展示线段\n",
    "    '''\n",
    "    line_img = np.zeros_like(frame)\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            for x1, y1, x2, y2 in line:\n",
    "                cv2.line(line_img, (x1, y1), (x2, y2), line_color, line_width)\n",
    "    line_img = cv2.addWeighted(frame, 0.8, line_img, 1, 1)\n",
    "    return line_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def show(window_name, img):\n",
    "    def mouse_click(event, x, y, flags, para):\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:  # 左边鼠标点击\n",
    "            print('PIX(y,x):', y, x)\n",
    "            print(\"BGR:\", img[y, x])\n",
    "\n",
    "    cv2.namedWindow(window_name)\n",
    "    cv2.setMouseCallback(window_name, mouse_click)\n",
    "    cv2.imshow(window_name, img)\n",
    "    if cv2.waitKey(0) == ord(\"q\"):\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "def scanLR(src: np.ndarray, step=1, visual=False):\n",
    "    \"\"\"扫线检测左右车道线\n",
    "    因为对图像的最底部做扫线的时候默认使用终点，因此其值不准，后面拟合线或者判断的时候应该忽略底部的行（从img.shape[0] - 1 - step开始）\n",
    "\n",
    "    Args:\n",
    "        mask (np.ndarray): 输入的二值化图像\n",
    "        step (int, optional): 扫描步长. Defaults to 1.\n",
    "\n",
    "    \"\"\"\n",
    "    visual_img = np.zeros((src.shape[0], src.shape[1], 3), dtype=np.uint8)\n",
    "    middle_line_mask = np.zeros((src.shape[0], src.shape[1]), dtype=np.uint8)\n",
    "    # 提取黄色部分\n",
    "    # 黄色的值范围\n",
    "    lower_hsv = np.array([23, 43, 46])\n",
    "    upper_hsv = np.array([34, 255, 255])\n",
    "\n",
    "    img2 = cv2.cvtColor(src, cv2.COLOR_BGR2HSV)\n",
    "    mask = cv2.inRange(img2, lower_hsv, upper_hsv)\n",
    "\n",
    "    # 黄色部分识别降噪，使用开运算的方式，先腐蚀再膨胀，kernel的大小要根据情况适度调整，kernel越大修改的粒度就越大，最终结果是大块的黄色更容易保留\n",
    "    # kernel = np.ones((3, 3), np.uint8)\n",
    "    # mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "    \n",
    "    # middle[y] 表示第y行道路的中点坐标\n",
    "    middle = np.zeros(mask.shape[0], dtype=np.int32)\n",
    "    left = np.zeros(mask.shape[0], dtype=np.int32)\n",
    "    right = np.zeros(mask.shape[0], dtype=np.int32)\n",
    "    # 初始化第一行\n",
    "    for i in range(mask.shape[0] - 1, mask.shape[0] - 1 - step + 1, -1):\n",
    "        middle[i] = mask.shape[1] // 2\n",
    "        right[i] = mask.shape[1] - 1\n",
    "        left[i] = 0\n",
    "    \n",
    "    for y in range(mask.shape[0] - 1 - step, 0, -step):\n",
    "        if y < (0 + step):\n",
    "            break\n",
    "        # 当前行标为y，上一行标为 y + step\n",
    "        # 扫描右边\n",
    "        for x in range(middle[y + step], mask.shape[1], 1):\n",
    "            # 找到了右边的车道线，黑白白的方式\n",
    "            if (x == mask.shape[1] - 1) or (x == mask.shape[1] - 2) or (mask[y][x] == 0 and mask[y][x + 1] == 255 and mask[y][x + 2] == 255):\n",
    "                # right[y] = x\n",
    "                right[y:y+step] = x\n",
    "                break\n",
    "        # 扫描左边\n",
    "        for x in range(middle[y + step], -1, -1):\n",
    "            # 找到了左边的车道线，黑白白的方式，前面的or表达式是为了防止后面下标记的越界\n",
    "            if (x == -1 + 1) or (x == -1 + 1 + 1) or (mask[y][x] == 0 and mask[y][x - 1] == 255 and mask[y][x - 2] == 255):\n",
    "                # left[y] = x\n",
    "                left[y:y+step] = x\n",
    "                break\n",
    "        # 计算step中所有行的中点\n",
    "        middle[y:y+step] = (left[y] + right[y]) //2\n",
    "\n",
    "        # middle[y] = (left[y] + right[y]) // 2\n",
    "        if visual:\n",
    "            # visual_img[y][left[y]] = [0, 0, 255]\n",
    "            # visual_img[y][right[y]] = [255, 0, 0]\n",
    "            # visual_img[y][middle[y]] = [0, 255, 0]\n",
    "\n",
    "            # --- 用以下切片方式会报错 ？？ \n",
    "            # print(y)\n",
    "            # visual_img[y:y+step][left[y]] = [0,0,255]\n",
    "            # visual_img[y:y+step][right[y]] = [255, 0, 0]\n",
    "            # visual_img[y:y+step][middle[y]] = [0, 0, 255]\n",
    "            # for i in range(step):\n",
    "            #     visual_img[y+i][left[y]] = [0,0,255]\n",
    "            #     visual_img[y+i][right[y]] = [255, 0,0]\n",
    "            #     visual_img[y+i][middle[y]] = [0,255,0]\n",
    "            #     middle_line_mask[y+i][middle[y]] = 255\n",
    "            for i in range(step):\n",
    "                visual_img[y:y+step, left[y], :] = [0,0,255]\n",
    "                visual_img[y:y+step, right[y], :] = [255, 0,0]\n",
    "                visual_img[y:y+step, middle[y], :] = [0,255,0]\n",
    "                middle_line_mask[y:y+step, middle[y]] = 255\n",
    "                \n",
    "    \n",
    "   \n",
    "    return left, right, middle, visual_img, middle_line_mask\n",
    "\n",
    "\n",
    "def road_type_detection(left: list, right: list, middle: list, visual_img: np.ndarray, visual=False):\n",
    "    \"\"\"判断道路类型\n",
    "\n",
    "    Args:\n",
    "        left (左): _description_\n",
    "        right (右): _description_\n",
    "        middle (中): _description_\n",
    "        visual_img (np.ndarray): 三线图\n",
    "\n",
    "    Returns:\n",
    "        str: \"straight\" or \"curve\"\n",
    "    \"\"\"\n",
    "    sum1: float = 0\n",
    "    sum2: float = 0\n",
    "\n",
    "    x_middle = visual_img.shape[1] // 2\n",
    "    y_middle = visual_img.shape[0] // 2\n",
    "\n",
    "    for i in range(y_middle, visual_img.shape[0]):\n",
    "        sum1 += (x_middle - middle[i])\n",
    "        sum2 += (middle[i] - x_middle) ** 2\n",
    "\n",
    "    print(\"sum1:\", sum1 / y_middle)\n",
    "    print(\"sum2:\", sum2 / y_middle)\n",
    "\n",
    "    road_type = \"\"\n",
    "    # 方差判断直道和弯道，3.2和18.5是经验值\n",
    "    if (sum2 > (3.2 * y_middle) ** 2 or sum1 / y_middle > 18.5 or sum1 / y_middle < -18.5):\n",
    "        road_type = \"curve\"\n",
    "    else:\n",
    "        road_type = \"straight\"\n",
    "    if visual: \n",
    "        road_type = road_type_detection(left, right, middle, visual_img)\n",
    "        # 在图片左上角显示文字\n",
    "        visual_img = cv2.putText(visual_img, road_type, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 1)\n",
    "    return road_type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240, 320, 3)\n",
      "sum1: 4.483333333333333\n",
      "sum2: 22.633333333333333\n",
      "sum1: 4.483333333333333\n",
      "sum2: 22.633333333333333\n",
      "straight\n",
      "[[[159  78 159   9]]\n",
      "\n",
      " [[156 199 157 228]]\n",
      "\n",
      " [[153 119 155 158]]\n",
      "\n",
      " [[157 194 157 205]]\n",
      "\n",
      " [[153  94 153 108]]\n",
      "\n",
      " [[155 170 156 183]]\n",
      "\n",
      " [[159 229 159 238]]\n",
      "\n",
      " [[154 109 154 118]]]\n",
      "[[[158, 240, 152, 120]]]\n"
     ]
    }
   ],
   "source": [
    "# todo 影响识别速度的参数：k分辨率压缩，scanLR step参数（取样横线数）\n",
    "img = cv2.imread('../../../data/traindatava/16_0.0_0.0.jpg')\n",
    "\n",
    "# 将图片分辨率压缩到原来的1 / k，加快处理速度\n",
    "k = 2\n",
    "img = cv2.resize(img, (img.shape[1] // k, img.shape[0] // k))\n",
    "print(img.shape)\n",
    "\n",
    "show('img', img)\n",
    "\n",
    "left, right, middle, visual_img, middle_line_mask = scanLR(img, step=5 ,visual=True)\n",
    "\n",
    "print(road_type_detection(left, right, middle, visual_img, visual=True))\n",
    "\n",
    "show('visual_img', visual_img)\n",
    "\n",
    "show('edges', middle_line_mask)\n",
    "\n",
    "middle_lines = detect_line(middle_line_mask)\n",
    "\n",
    "print(middle_lines)\n",
    "\n",
    "middle_lines = average_lines_old(img, middle_lines)\n",
    "\n",
    "print(middle_lines)\n",
    "\n",
    "img = display_line(img, middle_lines, (0, 255, 0), 2)\n",
    "\n",
    "show('img', img)\n",
    "\n",
    "\n",
    "# cv2.imwrite('visual_img.jpg', visual_img)\n",
    "# # canny边缘检测\n",
    "# yellow_edge = cv2.Canny(mask, 200, 400)\n",
    "\n",
    "# show('yellow_edge', yellow_edge)\n",
    "\n",
    "# # 通过开运算提取除水平线，再减去水平线\n",
    "# kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (15, 1))\n",
    "# yellow_edge2 = cv2.morphologyEx(yellow_edge, cv2.MORPH_OPEN, kernel)\n",
    "# yellow_edge2 = cv2.subtract(yellow_edge, yellow_edge2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检查拐点\n",
    "def detect_turn_point(img:np.ndarray, left: list, right: list, middle: list,  visual_img: np.ndarray,step: int = 5, roi: float = 0.5, visual=False):\n",
    "    \"\"\"深蓝色表示右下，浅蓝色表示右上，红色表示左下，粉色左上\n",
    "\n",
    "    Args:\n",
    "        img (np.ndarray): 图片\n",
    "        left (list): 左边界点\n",
    "        right (list): 有边界点\n",
    "        middle (list): 中点\n",
    "        visual_img (np.ndarray): 可是画的标记点图\n",
    "        step (int, optional): 扫描隔行数. Defaults to 5.\n",
    "        roi (float, optional): 处理区域. Defaults to 0.5.\n",
    "        visual (bool, optional): 是否可视化. Defaults to False.\n",
    "    \"\"\"\n",
    "\n",
    "    lower_left_point_finded = False\n",
    "    lower_right_point_finded = False\n",
    "    upper_left_point_finded = False\n",
    "    upper_right_point_finded = False\n",
    "    lower_left_point = None\n",
    "    lower_right_point = None\n",
    "    upper_left_point = None\n",
    "    upper_right_point = None\n",
    "\n",
    "    # 需要注意左边0或者1表示丢失左边线，右边shape[1] - 1或者shape[1] - 2表示丢失右边线，这是因为scanLR函数中的left[i] != 0和right[i] != img.shape[1] - 1的判断条件\n",
    "    for i in range(img.shape[0] - 1, math.floor(img.shape[0] * (1 - roi)), -step):\n",
    "        if lower_left_point_finded == False:\n",
    "            # 左下角未丢线\n",
    "            # if left[img.shape[0] - 1] != 0 and left[img.shape[0] - 1 - step] != 0:\n",
    "            # 丢线就跳过\n",
    "            if left[i] != 0 and left[i] != 1:\n",
    "                # 关于判定边界点跳变，一般采用经验值：1.5% - 5%，即两行之间的边界点横坐标差距为图像水平宽度的1.5% - 5%。该值越小对于跳变就越敏感，越大对于跳变就越不敏感。这里判断左边界突然左移。\n",
    "                if (left[i - step] - left[i]) / img.shape[1] < -0.015:\n",
    "                    p_x = np.max(left[i: img.shape[0]])\n",
    "                    p_y = np.argmax(left[i: img.shape[0]])  # 查找最大值的索引\n",
    "                    # 将索引转换为原图像的索引\n",
    "                    p_y = p_y + i\n",
    "                    lower_left_point = (p_y, p_x)\n",
    "                    print(\"lower_left_point:\", lower_left_point)\n",
    "                    lower_left_point_finded = True\n",
    "\n",
    "        # 右下角未丢线\n",
    "        # if right[img.shape[0] - 1] != img.shape[1] and right[img.shape[0] - 1 - step] != img.shape[1]:\n",
    "        if lower_right_point_finded == False:\n",
    "            # 丢线就跳过\n",
    "            if right[i] != img.shape[1] - 1 and right[i] != img.shape[1] - 2:\n",
    "                # 关于判定边界点跳变，一般采用经验值：1.5% - 5%，即两行之间的边界点横坐标差距为图像水平宽度的1.5% - 5%。该值越小对于跳变就越敏感，越大对于跳变就越不敏感，这里判断突然增大\n",
    "                if (right[i - step] - right[i]) / img.shape[1] > 0.015:\n",
    "                    p_x = np.min(right[i: img.shape[0]])\n",
    "                    p_y = np.argmin(right[i: img.shape[0]])  # 查找最小值的索引\n",
    "                    # 将索引转换为原图像的索引\n",
    "                    p_y = p_y + i\n",
    "                    lower_right_point = (p_y, p_x)\n",
    "                    print(\"lower_right_point:\", lower_right_point)\n",
    "                    lower_right_point_finded = True\n",
    "\n",
    "        if upper_left_point_finded == False:\n",
    "            # 关于判定边界点跳变，一般认为从丢线突变到有线，是一个较大的跳变，这里判断本行左边界本来丢线，突然出现，这里用经验值，放置丢线行的小干扰\n",
    "            if (left[i] == 0 or left[i] == 1) and left[i - step] / img.shape[1] > 0.20:\n",
    "                upper_left_point = (i - step, left[i - step])\n",
    "                print(\"upper_left_point:\", upper_left_point)\n",
    "                upper_left_point_finded = True\n",
    "\n",
    "        if upper_right_point_finded == False:\n",
    "            if right[i] == img.shape[1] - 1:\n",
    "                print(right[i], right[i - step])\n",
    "            if (right[i] == img.shape[1] - 1 or right[i] == img.shape[1] - 2) and (img.shape[1] - 1 - right[i - step]) / img.shape[1] > 0.20:\n",
    "                upper_right_point = (i - step, right[i - step])\n",
    "                print(\"upper_right_point:\", upper_right_point)\n",
    "                upper_right_point_finded = True\n",
    "\n",
    "        if lower_left_point_finded and lower_right_point_finded and upper_left_point_finded and upper_right_point_finded:\n",
    "            # 标记拐点\n",
    "            break\n",
    "    # T形路口左补线\n",
    "    if upper_left_point_finded == True  and lower_left_point_finded == True :\n",
    "        y_start = lower_left_point[0]\n",
    "        y_end = upper_left_point[0]\n",
    "        x_start = lower_left_point[1]\n",
    "        x_end = upper_left_point[1]\n",
    "        slope = (x_end - x_start) / (y_end - y_start)\n",
    "        for i in range(y_start, y_end, -1):\n",
    "            if visual:\n",
    "                visual_img[i, left[i]] = [0, 0, 0] # 删除原来的可视化点\n",
    "                visual_img[i, middle[i]] = [0, 0, 0] # 删除原来的可视化点\n",
    "            # 更新边界点和中线点\n",
    "            left[i] = int(x_start + slope * (i - y_start))\n",
    "            if left[i] < 0:\n",
    "                left[i] = 0\n",
    "            middle[i] = int((left[i] + right[i]) / 2)\n",
    "            if visual:\n",
    "                visual_img[i, left[i]] = [0, 0, 255] # 添加新的可视化点\n",
    "                visual_img[i, middle[i]] = [0, 255, 0] # 添加新的可视化点\n",
    "    # T形路口右补线\n",
    "    if upper_right_point_finded == True and lower_right_point_finded == True :\n",
    "        y_start = lower_right_point[0]\n",
    "        y_end = upper_right_point[0]\n",
    "        x_start = lower_right_point[1]\n",
    "        x_end = upper_right_point[1]\n",
    "        slope = (x_end - x_start) / (y_end - y_start)\n",
    "        for i in range(y_start, y_end, -1):\n",
    "            if visual:\n",
    "                visual_img[i, right[i]] = [0, 0, 0] # 删除原来的可视化点\n",
    "                visual_img[i, middle[i]] = [0, 0, 0] # 删除原来的可视化点\n",
    "            # 更新边界点和中线点\n",
    "            right[i] = int(x_start + slope * (i - y_start)) \n",
    "            if right[i] > img.shape[1] - 1:\n",
    "                right[i] = img.shape[1] - 1\n",
    "            middle[i] = int((left[i] + right[i]) / 2)\n",
    "            if visual:\n",
    "                visual_img[i, right[i]] = [255, 0, 0] # 添加新的可视化点\n",
    "                visual_img[i, middle[i]] = [0, 255, 0] # 添加新的可视化点\n",
    "\n",
    "\n",
    "    if visual:\n",
    "        # 记录的拐点坐标是用的y,x，所以要[::-1]反转一下y和x的顺序\n",
    "        if lower_left_point_finded == True:\n",
    "            visual_img = cv2.circle(\n",
    "                visual_img, lower_left_point[::-1], 5, (50, 0, 255), -1)\n",
    "        if lower_right_point_finded == True:\n",
    "            visual_img = cv2.circle(\n",
    "                visual_img, lower_right_point[::-1], 5, (255, 50, 0), -1)\n",
    "        if upper_left_point_finded == True:\n",
    "            visual_img = cv2.circle(\n",
    "                visual_img, upper_left_point[::-1], 5, (255, 0, 255), -1)\n",
    "        if upper_right_point_finded == True:\n",
    "            visual_img = cv2.circle(\n",
    "                visual_img, upper_right_point[::-1], 5, (255, 255, 0), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "639 638\n",
      "lower_right_point: (419, 573)\n",
      "upper_right_point: (249, 435)\n",
      "639 638\n",
      "lower_right_point: (404, 567)\n",
      "lower_left_point: (384, 51)\n",
      "upper_right_point: (249, 470)\n",
      "upper_left_point: (244, 190)\n"
     ]
    }
   ],
   "source": [
    "# test 检查拐点\n",
    "\n",
    "# img = cv2.imread(\"../../../data/traindatava/1547_0.06_-0.04.jpg\")\n",
    "\n",
    "# left, right, middle, visual_img, middle_line_mask = scanLR(img, step=5 ,visual=True)\n",
    "\n",
    "# detect_turn_point(img, left, right, middle, visual_img=visual_img,step=5, visual=True)\n",
    "\n",
    "# show('visual_img', visual_img)\n",
    "\n",
    "# 检查T形路口补线\n",
    "\n",
    "img = cv2.imread(r\"../../../data/traindatava/87_0.1_0.0.jpg\")\n",
    "\n",
    "left, right, middle, visual_img, middle_line_mask = scanLR(img, step=5 ,visual=True)\n",
    "\n",
    "detect_turn_point(img, left, right, middle, visual_img=visual_img,step=5, visual=True)\n",
    "\n",
    "show('visual_img', visual_img)\n",
    "\n",
    "# 检查十字路口补线\n",
    "\n",
    "img = cv2.imread(\"../../../data/traindatava/1547_0.06_-0.04.jpg\")\n",
    "\n",
    "left, right, middle, visual_img, middle_line_mask = scanLR(img, step=5 ,visual=True)\n",
    "\n",
    "detect_turn_point(img, left, right, middle, visual_img=visual_img,step=5, visual=True)\n",
    "\n",
    "show('visual_img', visual_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([  0,   1,   2,   3,   4,   5,   6,   7,   8, 479], dtype=int64),)\n"
     ]
    }
   ],
   "source": [
    "# 返回left == 0的索引\n",
    "print(np.where(left == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIX(y,x): 181 227\n",
      "BGR: [101 107  88]\n",
      "PIX(y,x): 184 16\n",
      "BGR: [147 170 172]\n",
      "PIX(y,x): 188 598\n",
      "BGR: [129 138 141]\n",
      "PIX(y,x): 187 2\n",
      "BGR: [163 185 180]\n",
      "PIX(y,x): 192 602\n",
      "BGR: [110 118 125]\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(r\"../../../data/traindatava/1534_0.07_-0.03.jpg\")\n",
    "\n",
    "show('img', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "img_match() missing 2 required positional arguments: 'kp2' and 'des2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mf:\\dataFileForAll\\Pros\\pythonPros\\venvForIpynb\\src\\Fixed-Map\\transbot\\transbot_fixed_map.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/dataFileForAll/Pros/pythonPros/venvForIpynb/src/Fixed-Map/transbot/transbot_fixed_map.ipynb#X15sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     result \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mdrawMatchesKnn(img, kp1, target, kp2, matches, \u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdraw_params)\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/dataFileForAll/Pros/pythonPros/venvForIpynb/src/Fixed-Map/transbot/transbot_fixed_map.ipynb#X15sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n\u001b[1;32m---> <a href='vscode-notebook-cell:/f%3A/dataFileForAll/Pros/pythonPros/venvForIpynb/src/Fixed-Map/transbot/transbot_fixed_map.ipynb#X15sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m show(\u001b[39m'\u001b[39m\u001b[39mresult\u001b[39m\u001b[39m'\u001b[39m, img_match(img, target, sift, flann))\n",
      "\u001b[1;31mTypeError\u001b[0m: img_match() missing 2 required positional arguments: 'kp2' and 'des2'"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(\"../../../data/traindatava/1571_0.09_0.0.jpg\")\n",
    "target = cv2.imread(\"../../../data/turn_left.jpg\")\n",
    "\n",
    "sift = cv2.SIFT_create()\n",
    "kp2, des2 = sift.detectAndCompute(target, None)\n",
    "# 设置FLANN匹配器\n",
    "FLANN_INDEX_KDTREE = 0\n",
    "indexParams = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
    "searchParams = dict(checks=50)\n",
    "flann = cv2.FlannBasedMatcher(indexParams, searchParams)\n",
    "def img_match(img, target, sift, flann, kp2, des2):\n",
    "    kp1, des1 = sift.detectAndCompute(img, None)\n",
    "    matches = flann.knnMatch(des1, des2, k=2)\n",
    "\n",
    "    matchesMask = [[0, 0] for i in range(len(matches))]\n",
    "    for i, (m, n) in enumerate(matches):\n",
    "        # 丢弃小于0.7的匹配\n",
    "        if m.distance < 0.7 * n.distance:\n",
    "            matchesMask[i] = [1, 0]\n",
    "    draw_params = dict(matchColor=(0, 255, 0), singlePointColor=(255, 0, 0), matchesMask=matchesMask, flags=0)\n",
    "    result = cv2.drawMatchesKnn(img, kp1, target, kp2, matches, None, **draw_params)\n",
    "    return result\n",
    "\n",
    "show('result', img_match(img, target, sift, flann, kp2, des2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "319 318\n",
      "sum1: 4.283333333333333\n",
      "sum2: 21.116666666666667\n",
      "sum1: 4.283333333333333\n",
      "sum2: 21.116666666666667\n",
      "straight\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'img_match' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mf:\\dataFileForAll\\Pros\\pythonPros\\venvForIpynb\\src\\Fixed-Map\\transbot\\transbot_fixed_map.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/dataFileForAll/Pros/pythonPros/venvForIpynb/src/Fixed-Map/transbot/transbot_fixed_map.ipynb#W5sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m \u001b[39m# ------\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/dataFileForAll/Pros/pythonPros/venvForIpynb/src/Fixed-Map/transbot/transbot_fixed_map.ipynb#W5sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m cv2\u001b[39m.\u001b[39mimshow(\u001b[39m\"\u001b[39m\u001b[39mmain\u001b[39m\u001b[39m\"\u001b[39m, img)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/f%3A/dataFileForAll/Pros/pythonPros/venvForIpynb/src/Fixed-Map/transbot/transbot_fixed_map.ipynb#W5sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m cv2\u001b[39m.\u001b[39mimshow(\u001b[39m\"\u001b[39m\u001b[39mresult\u001b[39m\u001b[39m\"\u001b[39m, img_match(img, target, sift, flann, kp2, des2))\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/dataFileForAll/Pros/pythonPros/venvForIpynb/src/Fixed-Map/transbot/transbot_fixed_map.ipynb#W5sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m keycode \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mwaitKey(\u001b[39m30\u001b[39m) \u001b[39m&\u001b[39m \u001b[39m0XFF\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/dataFileForAll/Pros/pythonPros/venvForIpynb/src/Fixed-Map/transbot/transbot_fixed_map.ipynb#W5sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m \u001b[39mif\u001b[39;00m keycode \u001b[39m==\u001b[39m \u001b[39m27\u001b[39m:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'img_match' is not defined"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# 视频处理，读取视频文件，逐帧显示，窗口右下角显示帧率\n",
    "cap = cv2.VideoCapture(\"../../../data/output.mp4\")\n",
    "\n",
    "target = cv2.imread(\"../../../data/turn_left.jpg\")\n",
    "\n",
    "sift = cv2.SIFT_create()\n",
    "kp2, des2 = sift.detectAndCompute(target, None)\n",
    "# 设置FLANN匹配器\n",
    "FLANN_INDEX_KDTREE = 0\n",
    "indexParams = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
    "searchParams = dict(checks=50)\n",
    "flann = cv2.FlannBasedMatcher(indexParams, searchParams)\n",
    "\n",
    "if cap.isOpened():\n",
    "    window_handle = cv2.namedWindow(\"main\", cv2.WINDOW_AUTOSIZE)\n",
    "    while cv2.getWindowProperty(\"main\", 0) >= 0:\n",
    "        ret_val, img = cap.read()\n",
    "        if ret_val == False:\n",
    "            break\n",
    "        # ------\n",
    "        # todo 影响识别速度的参数：k分辨率压缩，scanLR step参数（取样横线数）\n",
    "        # 将图片分辨率压缩到原来的1 / k，加快处理速度\n",
    "        k = 2\n",
    "        img = cv2.resize(img, (img.shape[1] // k, img.shape[0] // k))\n",
    "\n",
    "        left, right, middle, visual_img, middle_line_mask = scanLR(img, step=5 ,visual=True)\n",
    "        \n",
    "        detect_turn_point(img, left, right, middle, visual_img=visual_img,step=5, visual=True)\n",
    "\n",
    "        print(road_type_detection(left, right, middle, visual_img, visual=True))\n",
    "\n",
    "        middle_lines = detect_line(middle_line_mask[img.shape[0] // 2:])\n",
    "\n",
    "        middle_lines = average_lines_old(img, middle_lines)\n",
    "\n",
    "        img = display_line(img, middle_lines, (0, 255, 0), 2)\n",
    "\n",
    "        cv2.imshow('visual_img', visual_img)\n",
    "\n",
    "        # 仅放入下半部分，提高识别速度\n",
    "        cv2.imshow('half_visual_img', visual_img[visual_img.shape[0] // 2:])\n",
    "\n",
    "        cv2.imshow(\"half_middle_line_mask\", middle_line_mask[img.shape[0] // 2:])\n",
    "\n",
    "        # ------\n",
    "        cv2.imshow(\"main\", img)\n",
    "        cv2.imshow(\"result\", img_match(img, target, sift, flann, kp2, des2))\n",
    "        keycode = cv2.waitKey(30) & 0XFF\n",
    "        if keycode == 27:\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIX: 520 62\n",
      "BGR: 0\n",
      "left_lines [[[  0 451 177 240]]\n",
      "\n",
      " [[  0 421 145 248]]\n",
      "\n",
      " [[  0 426 168 240]]\n",
      "\n",
      " [[  0 420  97 296]]\n",
      "\n",
      " [[  0 422 158 240]]\n",
      "\n",
      " [[  0 447 174 240]]\n",
      "\n",
      " [[  0 454  69 372]]\n",
      "\n",
      " [[  0 452 178 240]]\n",
      "\n",
      " [[  0 423 159 240]]\n",
      "\n",
      " [[  0 445 172 240]]\n",
      "\n",
      " [[  0 434 169 240]]\n",
      "\n",
      " [[  0 455  65 378]]\n",
      "\n",
      " [[  0 450 176 240]]\n",
      "\n",
      " [[  0 425 167 240]]\n",
      "\n",
      " [[  0 458  65 380]]\n",
      "\n",
      " [[  0 418  75 318]]\n",
      "\n",
      " [[  0 463  60 391]]\n",
      "\n",
      " [[  0 413  69 325]]\n",
      "\n",
      " [[  0 436 170 240]]\n",
      "\n",
      " [[  0 412  52 343]]\n",
      "\n",
      " [[  0 407  43 352]]\n",
      "\n",
      " [[  0 461  64 384]]\n",
      "\n",
      " [[  0 405  36 358]]\n",
      "\n",
      " [[  0 411  50 345]]\n",
      "\n",
      " [[  1 462  42 415]]\n",
      "\n",
      " [[  0 427 162 247]]\n",
      "\n",
      " [[  0 437 171 240]]\n",
      "\n",
      " [[  0 424 165 240]]\n",
      "\n",
      " [[  1 419 121 271]]\n",
      "\n",
      " [[  1 465  21 450]]\n",
      "\n",
      " [[  1 464  29 435]]\n",
      "\n",
      " [[  0 440 173 240]]\n",
      "\n",
      " [[  0 415  92 301]]\n",
      "\n",
      " [[ 30 386 157 240]]\n",
      "\n",
      " [[ 98 295 152 244]]\n",
      "\n",
      " [[  0 429 169 241]]\n",
      "\n",
      " [[  4 465  30 431]]\n",
      "\n",
      " [[112 280 155 240]]\n",
      "\n",
      " [[  5 465  19 448]]\n",
      "\n",
      " [[  7 412 120 273]]\n",
      "\n",
      " [[ 86 307 163 240]]\n",
      "\n",
      " [[  0 409  44 352]]\n",
      "\n",
      " [[144 258 164 240]]\n",
      "\n",
      " [[ 42 376 161 240]]\n",
      "\n",
      " [[  6 465  28 441]]\n",
      "\n",
      " [[  2 416  82 311]]\n",
      "\n",
      " [[  2 465  41 417]]\n",
      "\n",
      " [[  0 442 173 243]]\n",
      "\n",
      " [[  0 459  64 383]]\n",
      "\n",
      " [[  0 428  74 361]]\n",
      "\n",
      " [[  0 404  17 382]]\n",
      "\n",
      " [[ 55 340 166 240]]\n",
      "\n",
      " [[  0 430  17 454]]\n",
      "\n",
      " [[  8 465  20 453]]\n",
      "\n",
      " [[  0 456  65 379]]\n",
      "\n",
      " [[ 23 393 141 252]]\n",
      "\n",
      " [[  0 441  60 379]]\n",
      "\n",
      " [[  1 463  29 442]]\n",
      "\n",
      " [[  1 439  45 389]]\n",
      "\n",
      " [[ 20 387  57 339]]\n",
      "\n",
      " [[166 256 179 240]]\n",
      "\n",
      " [[ 72 323  84 362]]\n",
      "\n",
      " [[  4 426  65 373]]\n",
      "\n",
      " [[  7 420  79 355]]\n",
      "\n",
      " [[ 51 365 162 241]]\n",
      "\n",
      " [[ 26 387 111 282]]\n",
      "\n",
      " [[ 11 452  28 432]]]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 提取感兴趣区域\n",
    "left_roi = region_of_interest(mask, 'left')\n",
    "right_roi = region_of_interest(mask, 'right')\n",
    "\n",
    "show('left_roi', left_roi)\n",
    "show('right_roi', right_roi)\n",
    "\n",
    "# 基于霍夫变换的直线检测\n",
    "left_lines = detect_line(left_roi)\n",
    "right_lines = detect_line(right_roi)\n",
    "\n",
    "print('left_lines', left_lines)\n",
    "print(type(left_lines))\n",
    "\n",
    "# 小线段聚类\n",
    "# 旧的聚类\n",
    "left_lines_old = average_lines_old(img, left_lines, 'left')\n",
    "right_lines_old = average_lines_old(img, right_lines, 'right')\n",
    "left_lines = average_lines(img, left_lines, 'left')\n",
    "right_lines = average_lines(img, right_lines, 'right')\n",
    "\n",
    "# 在原图上展示线段\n",
    "img = display_line(img, left_lines_old, (0, 255, 0), 1)\n",
    "img = display_line(img, right_lines_old, (0, 255, 0), 1)\n",
    "img = display_line(img, left_lines, (0, 0, 255), 2)\n",
    "img = display_line(img, right_lines, (0, 0, 255), 2)\n",
    "\n",
    "# color_and_edge = np.hstack((yellow_edge, yellow_edge2))\n",
    "# 将left_roi, right_roi合成一张图\n",
    "roi = cv2.addWeighted(left_roi, 1, right_roi, 1, 1)\n",
    "\n",
    "# cv2.imshow(\"D435-color_edge\", color_and_edge)\n",
    "show(\"D435-roi\", img)\n",
    "show(\"D435\", img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# canny边缘检测\n",
    "yellow_edge = cv2.Canny(mask, 200, 400)\n",
    "\n",
    "# 通过开运算提取除水平线，再减去水平线\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (15, 1))\n",
    "yellow_edge2 = cv2.morphologyEx(yellow_edge, cv2.MORPH_OPEN, kernel)\n",
    "yellow_edge2 = cv2.subtract(yellow_edge, yellow_edge2)\n",
    "\n",
    "# color_and_edge = np.hstack((yellow_edge, yellow_edge2))\n",
    "# 将left_roi, right_roi合成一张图\n",
    "roi = cv2.addWeighted(left_roi, 1, right_roi, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook transbot_fixed_map.ipynb to script\n",
      "[NbConvertApp] Writing 22140 bytes to transbot_fixed_map.py\n"
     ]
    }
   ],
   "source": [
    "# 转化为py文件\n",
    "!jupyter nbconvert --to script transbot_fixed_map.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvForIpynb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31b1400b2234a3897e1a0f341592b81d59b7fa378c5bbe160bb3b32387dc2409"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
